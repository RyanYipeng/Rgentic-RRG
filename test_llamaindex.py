"""
æµ‹è¯•2: LlamaIndex å¯¹æ¯”æµ‹è¯•
- ä½¿ç”¨ LlamaIndex çš„ Ollama LLM
- å¯¹æ¯”çº¯æ¨¡å‹å›ç­”å’Œ RAG å·¥å…·å¢å¼ºå›ç­”
- å±•ç¤ºå·¥å…·è°ƒç”¨çš„æ•ˆæœ
- ä¸éœ€è¦å¯åŠ¨ server.py
"""

from llama_index.core import Settings
from llama_index.llms.ollama import Ollama
from rag_app import Retriever, QdrantVDB, EmbedData
import os
import requests
from dotenv import load_dotenv

load_dotenv()

MODEL = "qwen2.5:7b-instruct"   

print("=" * 80)
print("ğŸ§ª æµ‹è¯•2: LlamaIndex å¯¹æ¯”æµ‹è¯•")
print("=" * 80)

# åˆå§‹åŒ– LlamaIndex Ollama LLM
print("\nğŸ¤– åˆå§‹åŒ– LlamaIndex Ollama LLM...")
llm = Ollama(
    model=MODEL,
    base_url="http://localhost:11434",
    temperature=0.7,
    request_timeout=120.0,
)
Settings.llm = llm
print("âœ… LLM å°±ç»ª\n")

# åˆå§‹åŒ– RAG å·¥å…·
print("ğŸ“š åˆå§‹åŒ– RAG å·¥å…·...")
embed = EmbedData()
vdb = QdrantVDB(collection="ml_faq_collection", vector_size=embed.dim)
retriever = Retriever(vdb, embed)
print("âœ… RAG å·¥å…·å°±ç»ª\n")


def pure_llama_answer(question: str) -> str:
    """çº¯ LlamaIndex LLM å›ç­”ï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼‰"""
    prompt = f"è¯·ç”¨ä¸­æ–‡ç®€æ´å›ç­”ï¼š{question}"
    response = llm.complete(prompt)
    return str(response).strip()


def rag_llama_answer(question: str) -> str:
    """ä½¿ç”¨ RAG å·¥å…· + LlamaIndex LLM å›ç­”"""
    # ä½¿ç”¨ RAG å·¥å…·æ£€ç´¢çŸ¥è¯†åº“
    context = retriever.search(question, k=2)
    
    # æ„é€ å¸¦ä¸Šä¸‹æ–‡çš„æç¤ºè¯
    prompt = f"""åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼š

ã€çŸ¥è¯†åº“ã€‘
{context}

ã€é—®é¢˜ã€‘
{question}

ã€è¦æ±‚ã€‘è¯·ç”¨ä¸­æ–‡ç®€æ´å›ç­”

ã€å›ç­”ã€‘"""
    
    response = llm.complete(prompt)
    return str(response).strip()


def web_search(query: str, num: int = 3) -> str:
    """ç½‘ç»œæœç´¢å·¥å…·"""
    api_key = os.getenv("SERPER_API_KEY")
    if not api_key:
        return "âš ï¸ æœªé…ç½® SERPER_API_KEYï¼Œæ— æ³•ä½¿ç”¨ç½‘ç»œæœç´¢"
    
    try:
        resp = requests.post(
            "https://google.serper.dev/search",
            headers={"X-API-KEY": api_key, "Content-Type": "application/json"},
            json={"q": query, "num": num},
            timeout=10
        )
        results = resp.json().get("organic", [])
        if not results:
            return "æœªæ‰¾åˆ°æœç´¢ç»“æœ"
        
        output = []
        for i, item in enumerate(results[:num], 1):
            output.append(f"{i}. {item.get('title', '')}")
            output.append(f"   {item.get('snippet', '')}")
            output.append(f"   {item.get('link', '')}")
        return "\n".join(output)
    except Exception as e:
        return f"âŒ æœç´¢å¤±è´¥: {e}"


def web_search_llama_answer(question: str) -> str:
    """ä½¿ç”¨ç½‘ç»œæœç´¢ + LlamaIndex LLM å›ç­”"""
    # 1. ä½¿ç”¨ç½‘ç»œæœç´¢è·å–ä¿¡æ¯
    search_results = web_search(question, num=2)
    
    # 2. å°†æœç´¢ç»“æœæä¾›ç»™ LlamaIndex LLM
    prompt = f"""åŸºäºä»¥ä¸‹ç½‘ç»œæœç´¢ç»“æœå›ç­”é—®é¢˜ï¼š

ã€æœç´¢ç»“æœã€‘
{search_results}

ã€é—®é¢˜ã€‘
{question}

ã€è¦æ±‚ã€‘è¯·ç”¨ä¸­æ–‡ç®€æ´å›ç­”ï¼Œç»¼åˆæœç´¢ç»“æœçš„ä¿¡æ¯

ã€å›ç­”ã€‘"""
    
    response = llm.complete(prompt)
    return str(response).strip()


# äº¤äº’å¼æµ‹è¯•
print("=" * 80)
print("ğŸ“ å¼€å§‹äº¤äº’å¼å¯¹æ¯”æµ‹è¯•")
print("=" * 80)
print("\nğŸ’¡ æç¤ºï¼š")
print("   1. è¾“å…¥é—®é¢˜è¿›è¡Œæµ‹è¯•")
print("   2. è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
print("   3. æ¯ä¸ªé—®é¢˜ä¼šå±•ç¤ºä¸‰ç§å›ç­”ï¼š")
print("      - çº¯ LlamaIndex LLMï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼‰")
print("      - RAG å·¥å…·å¢å¼ºï¼ˆä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
print("      - ç½‘ç»œæœç´¢å¢å¼ºï¼ˆä½¿ç”¨æœ€æ–°ä¿¡æ¯ï¼‰")
print("\n" + "=" * 80)

question_count = 0

while True:
    print("\n" + "â”€" * 80)
    question = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜: ").strip()
    
    if not question:
        print("âš ï¸  é—®é¢˜ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
        continue
    
    if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
        print("\nğŸ‘‹ é€€å‡ºæµ‹è¯•")
        break
    
    question_count += 1
    print(f"\n{' é—®é¢˜ ' + str(question_count) + ' ':=^80}")
    print(f"â“ {question}\n")
    
    # 1. çº¯ LlamaIndex LLM å›ç­”
    print("â”Œâ”€ ğŸ¤– çº¯ LlamaIndex LLM å›ç­”ï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼‰")
    print("â”‚")
    try:
        pure_answer = pure_llama_answer(question)
        for line in pure_answer.split('\n'):
            print(f"â”‚  {line}")
    except Exception as e:
        print(f"â”‚  âŒ é”™è¯¯: {e}")
    print("â””" + "â”€" * 78)
    
    print("")
    
    # 2. RAG å¢å¼ºå›ç­”
    print("â”Œâ”€ ğŸ”§ RAG å·¥å…· + LlamaIndex LLMï¼ˆä½¿ç”¨çŸ¥è¯†åº“ï¼‰")
    print("â”‚")
    try:
        rag_answer = rag_llama_answer(question)
        for line in rag_answer.split('\n'):
            print(f"â”‚  {line}")
    except Exception as e:
        print(f"â”‚  âŒ é”™è¯¯: {e}")
    print("â””" + "â”€" * 78)
    
    print("")
    
    # 3. ç½‘ç»œæœç´¢å¢å¼ºå›ç­”
    print("â”Œâ”€ ğŸŒ ç½‘ç»œæœç´¢ + LlamaIndex LLMï¼ˆä½¿ç”¨æœ€æ–°ä¿¡æ¯ï¼‰")
    print("â”‚")
    try:
        web_answer = web_search_llama_answer(question)
        for line in web_answer.split('\n'):
            print(f"â”‚  {line}")
    except Exception as e:
        print(f"â”‚  âŒ é”™è¯¯: {e}")
    print("â””" + "â”€" * 78)
    
    print("\nğŸ’¡ å¯¹æ¯”è¯´æ˜ï¼š")
    print("   â€¢ ç¬¬1ä¸ªï¼šçº¯ LlamaIndex LLMï¼ˆåŸºäºè®­ç»ƒæ•°æ®ï¼‰")
    print("   â€¢ ç¬¬2ä¸ªï¼šRAG å·¥å…·ï¼ˆåŸºäºæœ¬åœ°çŸ¥è¯†åº“ï¼‰")
    print("   â€¢ ç¬¬3ä¸ªï¼šç½‘ç»œæœç´¢ï¼ˆåŸºäºå®æ—¶ä¿¡æ¯ï¼‰")

print("\n" + "=" * 80)
print(f"âœ… æµ‹è¯•å®Œæˆï¼å…±æµ‹è¯•äº† {question_count} ä¸ªé—®é¢˜")
print("=" * 80)
print("\nğŸ“Š æ€»ç»“ï¼š")
print("   âœ“ å¯ä»¥æ¸…æ¥šçœ‹åˆ°ä¸‰ç§æ–¹å¼çš„åŒºåˆ«")
print("   âœ“ RAG å·¥å…·æä¾›çŸ¥è¯†åº“ä¸­çš„ç²¾ç¡®ä¿¡æ¯")
print("   âœ“ ç½‘ç»œæœç´¢æä¾›æœ€æ–°çš„å®æ—¶ä¿¡æ¯")
print("   âœ“ çº¯ LLM å›ç­”è¾ƒä¸ºé€šç”¨")
print("")
